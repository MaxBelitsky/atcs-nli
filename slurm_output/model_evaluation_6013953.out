============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
------------------------------------------------------------------------------------------------------------
Evaluating Mean
[2024-04-22 20:39:47,800] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 20:39:48,137] [INFO] [src.utils:utils.py:28] Found 18463 unique tokens
[2024-04-22 20:39:48,137] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 20:39:48,138] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 20:39:57,008] [INFO] [src.utils:utils.py:49] Found 17724 tokens with embeddings
[2024-04-22 20:39:57,137] [INFO] [root:binary.py:44] Generating sentence embeddings
[2024-04-22 20:39:58,175] [INFO] [root:binary.py:50] Generated sentence embeddings
[2024-04-22 20:39:58,176] [INFO] [root:validation.py:58] Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[2024-04-22 20:41:15,654] [INFO] [root:validation.py:89] Best param found at split 1: l2reg = 1e-05                 with score 77.41
[2024-04-22 20:42:28,355] [INFO] [root:validation.py:89] Best param found at split 2: l2reg = 1e-05                 with score 77.17
[2024-04-22 20:43:46,675] [INFO] [root:validation.py:89] Best param found at split 3: l2reg = 1e-05                 with score 77.08
[2024-04-22 20:45:09,587] [INFO] [root:validation.py:89] Best param found at split 4: l2reg = 1e-05                 with score 76.94
[2024-04-22 20:46:24,463] [INFO] [root:validation.py:89] Best param found at split 5: l2reg = 0.0001                 with score 77.02
[2024-04-22 20:46:27,917] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 20:46:28,023] [INFO] [src.utils:utils.py:28] Found 5348 unique tokens
[2024-04-22 20:46:28,024] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 20:46:28,024] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 20:46:35,605] [INFO] [src.utils:utils.py:49] Found 5311 tokens with embeddings
[2024-04-22 20:46:35,668] [INFO] [root:binary.py:44] Generating sentence embeddings
[2024-04-22 20:46:36,024] [INFO] [root:binary.py:50] Generated sentence embeddings
[2024-04-22 20:46:36,024] [INFO] [root:validation.py:58] Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
[2024-04-22 20:47:07,818] [INFO] [root:validation.py:89] Best param found at split 1: l2reg = 1e-05                 with score 80.2
[2024-04-22 20:47:38,037] [INFO] [root:validation.py:89] Best param found at split 2: l2reg = 0.0001                 with score 79.44
[2024-04-22 20:48:07,818] [INFO] [root:validation.py:89] Best param found at split 3: l2reg = 1e-05                 with score 79.44
[2024-04-22 20:48:41,110] [INFO] [root:validation.py:89] Best param found at split 4: l2reg = 0.0001                 with score 79.21
[2024-04-22 20:49:13,665] [INFO] [root:validation.py:89] Best param found at split 5: l2reg = 1e-05                 with score 79.44
[2024-04-22 20:49:14,806] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 20:49:14,878] [INFO] [src.utils:utils.py:28] Found 6222 unique tokens
[2024-04-22 20:49:14,878] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 20:49:14,878] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 20:49:21,638] [INFO] [src.utils:utils.py:49] Found 6204 tokens with embeddings
[2024-04-22 20:49:21,768] [INFO] [root:binary.py:44] Generating sentence embeddings
[2024-04-22 20:49:22,141] [INFO] [root:binary.py:50] Generated sentence embeddings
[2024-04-22 20:49:22,142] [INFO] [root:validation.py:58] Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
[2024-04-22 20:50:23,089] [INFO] [root:validation.py:89] Best param found at split 1: l2reg = 0.001                 with score 87.81
[2024-04-22 20:51:32,398] [INFO] [root:validation.py:89] Best param found at split 2: l2reg = 0.001                 with score 87.34
[2024-04-22 20:52:36,509] [INFO] [root:validation.py:89] Best param found at split 3: l2reg = 1e-05                 with score 87.68
[2024-04-22 20:53:49,654] [INFO] [root:validation.py:89] Best param found at split 4: l2reg = 0.0001                 with score 87.79
[2024-04-22 20:55:02,791] [INFO] [root:validation.py:89] Best param found at split 5: l2reg = 1e-05                 with score 87.8
[2024-04-22 20:55:07,345] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 20:55:07,693] [INFO] [src.utils:utils.py:28] Found 21020 unique tokens
[2024-04-22 20:55:07,693] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 20:55:07,693] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 20:55:15,063] [INFO] [src.utils:utils.py:49] Found 20049 tokens with embeddings
[2024-04-22 20:55:15,182] [INFO] [root:binary.py:44] Generating sentence embeddings
[2024-04-22 20:55:16,247] [INFO] [root:binary.py:50] Generated sentence embeddings
[2024-04-22 20:55:16,248] [INFO] [root:validation.py:58] Training pytorch-MLP-nhid0-adam-bs64 with (inner) 5-fold cross-validation
[2024-04-22 20:56:39,816] [INFO] [root:validation.py:89] Best param found at split 1: l2reg = 0.0001                 with score 91.11
[2024-04-22 20:58:09,399] [INFO] [root:validation.py:89] Best param found at split 2: l2reg = 0.0001                 with score 91.13
[2024-04-22 20:59:36,599] [INFO] [root:validation.py:89] Best param found at split 3: l2reg = 0.0001                 with score 91.52
[2024-04-22 21:01:06,480] [INFO] [root:validation.py:89] Best param found at split 4: l2reg = 1e-05                 with score 91.32
[2024-04-22 21:02:33,384] [INFO] [root:validation.py:89] Best param found at split 5: l2reg = 0.0001                 with score 91.09
[2024-04-22 21:02:36,512] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:02:37,656] [INFO] [src.utils:utils.py:28] Found 16183 unique tokens
[2024-04-22 21:02:37,656] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:02:37,657] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:02:45,359] [INFO] [src.utils:utils.py:49] Found 15738 tokens with embeddings
[2024-04-22 21:02:45,458] [INFO] [root:sst.py:62] Computing embedding for train
[2024-04-22 21:02:49,586] [INFO] [root:sst.py:76] Computed train embeddings
[2024-04-22 21:02:49,586] [INFO] [root:sst.py:62] Computing embedding for dev
[2024-04-22 21:02:49,674] [INFO] [root:sst.py:76] Computed dev embeddings
[2024-04-22 21:02:49,674] [INFO] [root:sst.py:62] Computing embedding for test
[2024-04-22 21:02:49,848] [INFO] [root:sst.py:76] Computed test embeddings
[2024-04-22 21:02:49,848] [INFO] [root:validation.py:203] Training pytorch-MLP-nhid0-adam-bs64 with standard validation..
[2024-04-22 21:04:40,076] [INFO] [root:validation.py:224] [('reg:1e-05', 80.05), ('reg:0.0001', 79.82), ('reg:0.001', 79.13), ('reg:0.01', 76.95)]
[2024-04-22 21:04:40,077] [INFO] [root:validation.py:228] Validation : best param found is reg = 1e-05 with score             80.05
[2024-04-22 21:04:40,077] [INFO] [root:validation.py:231] Evaluating...
[2024-04-22 21:05:10,982] [INFO] [root:trec.py:24] ***** Transfer task : TREC *****


[2024-04-22 21:05:11,033] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:05:11,124] [INFO] [src.utils:utils.py:28] Found 8766 unique tokens
[2024-04-22 21:05:11,125] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:05:11,125] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:05:18,679] [INFO] [src.utils:utils.py:49] Found 8535 tokens with embeddings
[2024-04-22 21:05:19,110] [INFO] [root:trec.py:66] Computed train embeddings
[2024-04-22 21:05:19,146] [INFO] [root:trec.py:74] Computed test embeddings
[2024-04-22 21:05:19,147] [INFO] [root:validation.py:128] Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation
[2024-04-22 21:06:33,795] [INFO] [root:validation.py:160] [('reg:1e-05', 73.37), ('reg:0.0001', 73.29), ('reg:0.001', 70.43), ('reg:0.01', 62.8)]
[2024-04-22 21:06:33,798] [INFO] [root:validation.py:164] Cross-validation : best param found is reg = 1e-05             with score 73.37
[2024-04-22 21:06:33,798] [INFO] [root:validation.py:167] Evaluating...
[2024-04-22 21:06:38,658] [INFO] [root:mrpc.py:25] ***** Transfer task : MRPC *****


[2024-04-22 21:06:38,700] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:06:39,071] [INFO] [src.utils:utils.py:28] Found 15665 unique tokens
[2024-04-22 21:06:39,071] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:06:39,072] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:06:45,820] [INFO] [src.utils:utils.py:49] Found 14755 tokens with embeddings
[2024-04-22 21:06:45,910] [INFO] [root:mrpc.py:58] Computing embedding for train
[2024-04-22 21:06:46,783] [INFO] [root:mrpc.py:78] Computed train embeddings
[2024-04-22 21:06:46,783] [INFO] [root:mrpc.py:58] Computing embedding for test
[2024-04-22 21:06:47,158] [INFO] [root:mrpc.py:78] Computed test embeddings
[2024-04-22 21:06:47,167] [INFO] [root:validation.py:128] Training pytorch-MLP-nhid0-adam-bs64 with 5-fold cross-validation
[2024-04-22 21:07:20,284] [INFO] [root:validation.py:160] [('reg:1e-05', 73.09), ('reg:0.0001', 72.82), ('reg:0.001', 72.6), ('reg:0.01', 71.59)]
[2024-04-22 21:07:20,284] [INFO] [root:validation.py:164] Cross-validation : best param found is reg = 1e-05             with score 73.09
[2024-04-22 21:07:20,284] [INFO] [root:validation.py:167] Evaluating...
[2024-04-22 21:07:22,349] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:07:22,640] [INFO] [src.utils:utils.py:28] Found 2314 unique tokens
[2024-04-22 21:07:22,641] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:07:22,641] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:07:29,814] [INFO] [src.utils:utils.py:49] Found 2310 tokens with embeddings
[2024-04-22 21:07:29,865] [INFO] [root:sick.py:167] Computing embedding for train
[2024-04-22 21:07:30,459] [INFO] [root:sick.py:185] Computed train embeddings
[2024-04-22 21:07:30,459] [INFO] [root:sick.py:167] Computing embedding for dev
[2024-04-22 21:07:30,524] [INFO] [root:sick.py:185] Computed dev embeddings
[2024-04-22 21:07:30,524] [INFO] [root:sick.py:167] Computing embedding for test
[2024-04-22 21:07:31,186] [INFO] [root:sick.py:185] Computed test embeddings
[2024-04-22 21:07:31,199] [INFO] [root:validation.py:203] Training pytorch-MLP-nhid0-adam-bs64 with standard validation..
[2024-04-22 21:07:42,625] [INFO] [root:validation.py:224] [('reg:1e-05', 72.4), ('reg:0.0001', 72.8), ('reg:0.001', 71.0), ('reg:0.01', 62.8)]
[2024-04-22 21:07:42,625] [INFO] [root:validation.py:228] Validation : best param found is reg = 0.0001 with score             72.8
[2024-04-22 21:07:42,625] [INFO] [root:validation.py:231] Evaluating...
[2024-04-22 21:07:45,954] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:07:46,240] [INFO] [src.utils:utils.py:28] Found 2314 unique tokens
[2024-04-22 21:07:46,240] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:07:46,240] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:07:53,118] [INFO] [src.utils:utils.py:49] Found 2310 tokens with embeddings
[2024-04-22 21:07:53,166] [INFO] [root:sick.py:63] Computing embedding for train
[2024-04-22 21:07:53,728] [INFO] [root:sick.py:82] Computed train embeddings
[2024-04-22 21:07:53,728] [INFO] [root:sick.py:63] Computing embedding for dev
[2024-04-22 21:07:53,788] [INFO] [root:sick.py:82] Computed dev embeddings
[2024-04-22 21:07:53,788] [INFO] [root:sick.py:63] Computing embedding for test
[2024-04-22 21:07:54,450] [INFO] [root:sick.py:82] Computed test embeddings
[2024-04-22 21:08:14,790] [INFO] [src.utils:utils.py:102] Finding all unique tokens
[2024-04-22 21:08:14,939] [INFO] [src.utils:utils.py:28] Found 8799 unique tokens
[2024-04-22 21:08:14,939] [INFO] [src.utils:utils.py:104] Aligning with GloVe vectors
[2024-04-22 21:08:14,939] [INFO] [torchtext.vocab.vectors:vectors.py:172] Loading vectors from .vector_cache/glove.840B.300d.txt.pt
[2024-04-22 21:08:22,160] [INFO] [src.utils:utils.py:49] Found 8493 tokens with embeddings
{'MR': {'devacc': 77.12, 'acc': 76.79, 'ndev': 10662, 'ntest': 10662}, 'CR': {'devacc': 79.55, 'acc': 78.01, 'ndev': 3775, 'ntest': 3775}, 'MPQA': {'devacc': 87.68, 'acc': 87.41, 'ndev': 10606, 'ntest': 10606}, 'SUBJ': {'devacc': 91.23, 'acc': 90.9, 'ndev': 10000, 'ntest': 10000}, 'SST2': {'devacc': 80.05, 'acc': 80.45, 'ndev': 872, 'ntest': 1821}, 'TREC': {'devacc': 73.37, 'acc': 81.4, 'ndev': 5452, 'ntest': 500}, 'MRPC': {'devacc': 73.09, 'acc': 71.83, 'f1': 80.65, 'ndev': 4076, 'ntest': 1725}, 'SICKEntailment': {'devacc': 72.8, 'acc': 77.13, 'ndev': 500, 'ntest': 4927}, 'SICKRelatedness': {'devpearson': 0.7163740919249292, 'pearson': 0.774025258540493, 'spearman': 0.6960101467212355, 'mse': 0.40837561272442446, 'yhat': array([3.00843598, 3.88102416, 1.00191392, ..., 3.4396517 , 4.2905089 ,
       4.4959979 ]), 'ndev': 500, 'ntest': 4927}, 'STS14': {'deft-forum': {'pearson': PearsonRResult(statistic=0.29810270306236775, pvalue=1.0934830388186529e-10), 'spearman': SignificanceResult(statistic=0.3434822411349732, pvalue=6.612705107861852e-14), 'nsamples': 450}, 'deft-news': {'pearson': PearsonRResult(statistic=0.653119586940386, pvalue=7.272325600641003e-38), 'spearman': SignificanceResult(statistic=0.6529670773450588, pvalue=7.660324765608231e-38), 'nsamples': 300}, 'headlines': {'pearson': PearsonRResult(statistic=0.5917233807936458, pvalue=4.865468353494059e-72), 'spearman': SignificanceResult(statistic=0.5471505520829678, pvalue=8.655920763293659e-60), 'nsamples': 750}, 'images': {'pearson': PearsonRResult(statistic=0.6179840556875652, pvalue=3.3711384988370953e-80), 'spearman': SignificanceResult(statistic=0.614463651195665, pvalue=4.6387983674589843e-79), 'nsamples': 750}, 'OnWN': {'pearson': PearsonRResult(statistic=0.5791338789003796, pvalue=2.1850260545081133e-68), 'spearman': SignificanceResult(statistic=0.6463331184521678, pvalue=6.390173271877557e-90), 'nsamples': 750}, 'tweet-news': {'pearson': PearsonRResult(statistic=0.5524065240391228, pvalue=3.8711498643577836e-61), 'spearman': SignificanceResult(statistic=0.5280349391884588, pvalue=4.454802837661674e-55), 'nsamples': 750}, 'all': {'pearson': {'mean': 0.5487450215705779, 'wmean': 0.5562714592068577}, 'spearman': {'mean': 0.5554052632332153, 'wmean': 0.5606516873076534}}}}
{'macro': 79.36125, 'micro': 82.03470496049454}

JOB STATISTICS
==============
Job ID: 6013953
Cluster: snellius
User/Group: scur0209/scur0209
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:39:00 core-walltime
Job Wall-clock time: 00:28:50
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
